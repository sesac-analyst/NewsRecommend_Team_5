{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 코랩에서 실행 권장(gpu 권장)\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import multiprocessing as mp\n",
    "from google.colab import files\n",
    "\n",
    "model = get_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "def get_document_embedding(sentences:list):\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get the sentence embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the embeddings for the [CLS] token (shape: [batch_size, hidden_size])\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    # Pool the sentence embeddings to create a single document embedding by averaging\n",
    "    document_embedding = torch.mean(cls_embeddings, dim=0)\n",
    "\n",
    "    return document_embedding.cpu().numpy()\n",
    "\n",
    "# 병렬화 위한 함수\n",
    "def process_sentence(sentences):\n",
    "    sentences = eval(sentences)  # Convert string to list\n",
    "    return get_document_embedding(sentences)\n",
    "\n",
    "# 멀티프로세싱 이용\n",
    "def compute_embeddings_in_parallel(data, num_workers=4):\n",
    "    with mp.Pool(processes=num_workers) as pool:\n",
    "        # Use multiprocessing Pool to compute embeddings in parallel\n",
    "        results = pool.map(process_sentence, data)\n",
    "    return results\n",
    "\n",
    "# 파일 불러오기\n",
    "with open(\"/content/month_sample3.csv\", encoding='utf-8') as f:\n",
    "    contents = f.read()\n",
    "cleaned_contents = contents.lstrip('\\ufeff')\n",
    "df = pd.read_csv(StringIO(cleaned_contents), index_col=0)\n",
    "\n",
    "# df에서 문서행 추출\n",
    "sam = df[\"clear_sentence_split\"]\n",
    "\n",
    "# worker 수 설정\n",
    "num_workers = mp.cpu_count()  # This will use all available CPU cores\n",
    "\n",
    "# 병렬 진행\n",
    "vector_list = compute_embeddings_in_parallel(sam, num_workers=num_workers)\n",
    "\n",
    "# 파일 저장\n",
    "vector_list.to_csv('/content/embedded_data.csv')\n",
    "files.download('/content/embedded.csv')\n",
    "\n",
    "print(\"Complete\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
