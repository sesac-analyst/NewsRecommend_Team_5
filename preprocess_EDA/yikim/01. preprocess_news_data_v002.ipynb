{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "daum_open_path = './data/daum_data/daum_data.csv'\n",
    "naver_open_path = './data/naver_data/news_naver_IT_contents_n.csv'\n",
    "\n",
    "daum_df = pd.read_csv(daum_open_path)\n",
    "naver_df = pd.read_csv(naver_open_path, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 830608 entries, 0 to 830607\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Unnamed: 0   830608 non-null  int64 \n",
      " 1   platform     830608 non-null  object\n",
      " 2   title        830604 non-null  object\n",
      " 3   category     830608 non-null  object\n",
      " 4   article_url  830608 non-null  object\n",
      " 5   date         830608 non-null  int64 \n",
      " 6   publisher    830604 non-null  object\n",
      " 7   content      828905 non-null  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 50.7+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292503 entries, 0 to 292502\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   article_url  292503 non-null  object\n",
      " 1   title        292487 non-null  object\n",
      " 2   reg_date     292474 non-null  object\n",
      " 3   publisher    292467 non-null  object\n",
      " 4   author       292462 non-null  object\n",
      " 5   sub_title    129386 non-null  object\n",
      " 6   content      291927 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 15.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "copy_daum_df = daum_df.copy()\n",
    "copy_naver_df = naver_df.copy()\n",
    "print(copy_daum_df.info())\n",
    "print(copy_naver_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 컬럼면 일치\n",
    "copy_daum_df.columns = ['','platform_id','title','category','article_url','publication_date','publisher_id','content']\n",
    "copy_naver_df.columns = ['article_url','title','publication_date','publisher_id','author','sub_title','content']\n",
    "\n",
    "# 날짜 형식 통일\n",
    "copy_daum_df['publication_date'] = pd.to_datetime(copy_daum_df['publication_date'], format='%Y%m%d', errors='coerce')\n",
    "copy_naver_df['publication_date'] = pd.to_datetime(copy_naver_df['publication_date'], errors='coerce')\n",
    "\n",
    "copy_daum_df['publication_date'] = copy_daum_df['publication_date'].dt.strftime('%Y-%m-%d')\n",
    "copy_naver_df['publication_date'] = copy_naver_df['publication_date'].dt.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>platform_id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>article_url</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>daum</td>\n",
       "      <td>롯데렌탈, 쏘카 지분 17.9% 추가 매입...2대 주주 지위</td>\n",
       "      <td>autos</td>\n",
       "      <td>https://v.daum.net/v/20230831212156741</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>오토타임즈</td>\n",
       "      <td>\\n\\n -총 32.9% 지분 보유로 2대 주주 지위 \\n\\n\\n -미래 모빌리티 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>daum</td>\n",
       "      <td>르노코리아, 주요모델 가격 인하… ‘가성비’로 승부수</td>\n",
       "      <td>autos</td>\n",
       "      <td>https://v.daum.net/v/20230831200507575</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>세계일보</td>\n",
       "      <td>최근 국내 시장에서 부진한 성적을 내고 있는 르노코리아자동차가 내년 신차 출시까지의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>daum</td>\n",
       "      <td>위기의 르노코리아…\"200만원 내렸다\" 가격 인하 승부수</td>\n",
       "      <td>autos</td>\n",
       "      <td>https://v.daum.net/v/20230831200116487</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>한국경제</td>\n",
       "      <td>'신차 부재' 여파로 올해 내수 시장서 고전을 면치 못하는 르노코리아자동차가 가격 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     platform_id                               title category  \\\n",
       "0  0        daum  롯데렌탈, 쏘카 지분 17.9% 추가 매입...2대 주주 지위    autos   \n",
       "1  1        daum       르노코리아, 주요모델 가격 인하… ‘가성비’로 승부수    autos   \n",
       "2  2        daum     위기의 르노코리아…\"200만원 내렸다\" 가격 인하 승부수    autos   \n",
       "\n",
       "                              article_url publication_date publisher_id  \\\n",
       "0  https://v.daum.net/v/20230831212156741       2023-08-31        오토타임즈   \n",
       "1  https://v.daum.net/v/20230831200507575       2023-08-31         세계일보   \n",
       "2  https://v.daum.net/v/20230831200116487       2023-08-31         한국경제   \n",
       "\n",
       "                                             content  \n",
       "0  \\n\\n -총 32.9% 지분 보유로 2대 주주 지위 \\n\\n\\n -미래 모빌리티 ...  \n",
       "1  최근 국내 시장에서 부진한 성적을 내고 있는 르노코리아자동차가 내년 신차 출시까지의...  \n",
       "2  '신차 부재' 여파로 올해 내수 시장서 고전을 면치 못하는 르노코리아자동차가 가격 ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_daum_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_url</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>author</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://n.news.naver.com/mnews/article/003/001...</td>\n",
       "      <td>삼성 中 시장에 300만원 초호화폰 내놓는 속사정</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>뉴시스</td>\n",
       "      <td>윤현성</td>\n",
       "      <td>삼성, '심계천하' 시리즈 신작 10월 출시 전망…300만원 육박할 듯 고가 프리미...</td>\n",
       "      <td>지난해 10월 중국 시장에 출시된 삼성전자 심계천하 'W23 5G'와 'W23 플립...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>��에 못미친데다</td>\n",
       "      <td>출시를 앞둔 새모델인 아이폰15프로 및 프로맥스 모델의 일부 디스플레이 부품이 신...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://n.news.naver.com/mnews/article/092/000...</td>\n",
       "      <td>애플 주가 4.8% 폭락…시총 3조 달러 무너졌다</td>\n",
       "      <td>2023-08-05</td>\n",
       "      <td>지디넷코리아</td>\n",
       "      <td>김익현</td>\n",
       "      <td>아이폰 등 HW매출 부진 실망감…올들어 최대 낙폭</td>\n",
       "      <td>애플 주가가 지난 해 9월 말 이후 가장 큰 폭으로 하락했다. 그 여파로 시가총액도...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_url  \\\n",
       "0  https://n.news.naver.com/mnews/article/003/001...   \n",
       "1                                          ��에 못미친데다   \n",
       "2  https://n.news.naver.com/mnews/article/092/000...   \n",
       "\n",
       "                                               title publication_date  \\\n",
       "0                        삼성 中 시장에 300만원 초호화폰 내놓는 속사정       2023-08-05   \n",
       "1   출시를 앞둔 새모델인 아이폰15프로 및 프로맥스 모델의 일부 디스플레이 부품이 신...              NaN   \n",
       "2                        애플 주가 4.8% 폭락…시총 3조 달러 무너졌다       2023-08-05   \n",
       "\n",
       "  publisher_id author                                          sub_title  \\\n",
       "0          뉴시스    윤현성  삼성, '심계천하' 시리즈 신작 10월 출시 전망…300만원 육박할 듯 고가 프리미...   \n",
       "1          NaN    NaN                                                NaN   \n",
       "2       지디넷코리아    김익현                        아이폰 등 HW매출 부진 실망감…올들어 최대 낙폭   \n",
       "\n",
       "                                             content  \n",
       "0  지난해 10월 중국 시장에 출시된 삼성전자 심계천하 'W23 5G'와 'W23 플립...  \n",
       "1                                                NaN  \n",
       "2  애플 주가가 지난 해 9월 말 이후 가장 큰 폭으로 하락했다. 그 여파로 시가총액도...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_naver_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760612/760612 [00:01<00:00, 628648.17it/s]\n",
      "100%|██████████| 760612/760612 [00:01<00:00, 492411.78it/s]\n",
      "100%|██████████| 760612/760612 [00:00<00:00, 874700.65it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 614041.54it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 510196.13it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 1288608.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "copy_daum_df.drop_duplicates(subset='article_url', keep='first', inplace=True)\n",
    "copy_daum_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "copy_daum_df.drop_duplicates(subset='content', keep='first', inplace=True)\n",
    "copy_daum_df.dropna(subset=['content'], inplace=True)\n",
    "\n",
    "copy_naver_df.drop_duplicates(subset='article_url', keep='first', inplace=True)\n",
    "copy_naver_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "copy_naver_df.drop_duplicates(subset='content', keep='first', inplace=True)\n",
    "copy_naver_df.dropna(subset=['content'], inplace=True)\n",
    "\n",
    "# 문장내 <>, [], 구문 제거(앞뒤 공백 제거 포함)\n",
    "copy_daum_df['clear_str'] = copy_daum_df['content'].progress_apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "copy_daum_df['clear_str'] = copy_daum_df['clear_str'].progress_apply(lambda x: re.sub(r'\\[.*?\\]', '', x))\n",
    "copy_daum_df['clear_str'] = copy_daum_df['clear_str'].progress_apply(lambda x: x.strip())\n",
    "\n",
    "copy_naver_df['clear_str'] = copy_naver_df['content'].progress_apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "copy_naver_df['clear_str'] = copy_naver_df['clear_str'].progress_apply(lambda x: re.sub(r'\\[.*?\\]', '', x))\n",
    "copy_naver_df['clear_str'] = copy_naver_df['clear_str'].progress_apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어별 처리 함수\n",
    "def process_words(words, del_words, stopwords):\n",
    "        processed_words=[]\n",
    "        for word in words:\n",
    "            if word == '기자':\n",
    "                if processed_words:\n",
    "                    processed_words.pop()\n",
    "                continue\n",
    "            \n",
    "            if any(del_word in word for del_word in del_words):\n",
    "                continue\n",
    "\n",
    "            if '@' in word:\n",
    "                continue\n",
    "            # word = re.sub(r'\\d+','', word)\n",
    "            word = re.sub(r'[^\\w\\s.]','', word)\n",
    "            \n",
    "            if re.search('[a-zA-Z]', word):\n",
    "                word = word.lower()\n",
    "            \n",
    "            for stopword in stopwords:\n",
    "                if word.endswith(stopword):\n",
    "                    word = word[:-len(stopword)]\n",
    "            \n",
    "            if len(word) <= 1:\n",
    "                continue\n",
    "                    \n",
    "            if word:\n",
    "                processed_words.append(word)\n",
    "        return processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리 단어들 목록\n",
    "press_name = set()\n",
    "\n",
    "press_name.update(copy_daum_df['publisher_id'].unique())\n",
    "press_name.update(copy_naver_df['publisher_id'].unique())\n",
    "\n",
    "press_name = list(press_name)\n",
    "\n",
    "stopword = ['기자', 'com', '.co', '저작권', '무단', '전재', '재배포', 'Copyr', 'copyr', '경향비즈'\n",
    "        '영상', '취재', '편집', '문의', '금지', '특파원', '아이뉴스', '한경', '뉴스', '보도합니다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760612/760612 [00:17<00:00, 43193.95it/s]\n",
      "100%|██████████| 760612/760612 [23:05<00:00, 548.81it/s]  \n",
      "100%|██████████| 255019/255019 [00:10<00:00, 23657.10it/s]\n",
      "100%|██████████| 255019/255019 [09:13<00:00, 460.87it/s]\n",
      "100%|██████████| 760612/760612 [00:00<00:00, 1497546.34it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 1461255.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# 단어로 정리\n",
    "copy_daum_df['split_word'] = copy_daum_df['clear_str'].progress_apply(lambda x: x.split())\n",
    "copy_daum_df['processed_words'] = copy_daum_df['split_word'].progress_apply(lambda words: process_words(words, press_name, stopword))\n",
    "\n",
    "copy_naver_df['split_word'] = copy_naver_df['clear_str'].progress_apply(lambda x: x.split())\n",
    "copy_naver_df['processed_words'] = copy_naver_df['split_word'].progress_apply(lambda words: process_words(words, press_name, stopword))\n",
    "\n",
    "\n",
    "# 단어 수 저장\n",
    "copy_daum_df['word_ctn'] = copy_daum_df['processed_words'].progress_apply(len)\n",
    "copy_naver_df['word_ctn'] = copy_naver_df['processed_words'].progress_apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760612/760612 [00:05<00:00, 141453.81it/s]\n",
      "100%|██████████| 255019/255019 [00:02<00:00, 126386.10it/s]\n",
      "100%|██████████| 760612/760612 [00:00<00:00, 1400614.89it/s]\n",
      "100%|██████████| 760612/760612 [00:29<00:00, 25909.96it/s]\n",
      "100%|██████████| 760612/760612 [00:00<00:00, 1648418.96it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 1275085.58it/s]\n",
      "100%|██████████| 255019/255019 [00:06<00:00, 41160.14it/s]\n",
      "100%|██████████| 255019/255019 [00:00<00:00, 1604521.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# 문장 만들기\n",
    "copy_daum_df['clear_sentence'] = copy_daum_df['processed_words'].progress_apply(lambda words: ' '.join(words))\n",
    "copy_naver_df['clear_sentence'] = copy_naver_df['processed_words'].progress_apply(lambda words: ' '.join(words))\n",
    "\n",
    "# 문장 수 저장\n",
    "copy_daum_df['letter_ctn'] = copy_daum_df['clear_sentence'].progress_apply(len)\n",
    "copy_daum_df['clear_sentence_split'] = copy_daum_df['clear_sentence'].progress_apply(lambda sentence: re.split(r'(?<!\\d)\\.(?!\\d)', sentence))\n",
    "copy_daum_df['sentence_ctn'] =  copy_daum_df['clear_sentence_split'].progress_apply(len)\n",
    "\n",
    "copy_naver_df['letter_ctn'] = copy_naver_df['clear_sentence'].progress_apply(len)\n",
    "copy_naver_df['clear_sentence_split'] = copy_naver_df['clear_sentence'].progress_apply(lambda sentence: re.split(r'(?<!\\d)\\.(?!\\d)', sentence))\n",
    "copy_naver_df['sentence_ctn'] =  copy_naver_df['clear_sentence_split'].progress_apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백란 제거 추가\n",
    "copy_daum_df = copy_daum_df[copy_daum_df['content'].str.strip().astype(bool)]\n",
    "copy_naver_df = copy_naver_df[copy_naver_df['content'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고유 id 만들기 함수\n",
    "def make_tag_id(url):\n",
    "    if 'daum' in url:\n",
    "        sent_id = f'd{url.split(\"/\")[-1][4:]}'\n",
    "    elif 'naver' in url:\n",
    "        sent_id = f'n{url.split(\"/\")[-2]}{url.split(\"/\")[-1]}'\n",
    "    else:\n",
    "        sent_id = 'unknwon_id'\n",
    "\n",
    "    return sent_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고유 id 데이터프레임 추가\n",
    "copy_daum_df['tag'] = copy_daum_df['article_url'].apply(make_tag_id)\n",
    "copy_naver_df['tag'] = copy_naver_df['article_url'].apply(make_tag_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_copy_daum_df = copy_daum_df[['tag','publication_date','article_url','letter_ctn', 'word_ctn', 'sentence_ctn', 'clear_sentence_split']]\n",
    "prog_copy_naver_df = copy_naver_df[['tag','publication_date','article_url','letter_ctn', 'word_ctn', 'sentence_ctn', 'clear_sentence_split']]\n",
    "\n",
    "all_prog_copy_df = pd.concat([prog_copy_daum_df, prog_copy_naver_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './data/01. preprocessed_data.csv'\n",
    "all_prog_copy_df.to_csv(save_path, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
