{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kobert_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 코랩에서 실행 권장(gpu 권장)\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from kobert_transformers import get_tokenizer, get_kobert_model\n",
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import multiprocessing as mp\n",
    "from google.colab import files\n",
    "\n",
    "model = get_kobert_model()\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "def get_document_embedding(sentences):\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Get the sentence embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the embeddings for the [CLS] token (shape: [batch_size, hidden_size])\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "    # Pool the sentence embeddings to create a single document embedding by averaging\n",
    "    document_embedding = torch.mean(cls_embeddings, dim=0)\n",
    "\n",
    "    return document_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_2024 = pd.read_csv(\"/content/drive/Othercomputers/갤럭시북4pro/workspace/july_2024.csv\", index_col=0)\n",
    "samples = list(july_2024['clear_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_list = []\n",
    "i = 0\n",
    "j = 0\n",
    "for doc in samples:\n",
    "  try:\n",
    "    embedded_list.append(get_document_embedding(doc))\n",
    "  except Exception as e:\n",
    "    i += 1\n",
    "    embedded_list.append('e')\n",
    "    print(f'에러발생 {i}회, index = {samples.index(doc)}')\n",
    "  if samples.index(doc) % 1000 == 0:\n",
    "    print(f'{j*1000}개 완료')\n",
    "    j += 1\n",
    "\n",
    "pd.DataFrame({'vector':embedded_list}).to_csv('/content/drive/Othercomputers/갤럭시북4pro/workspace/embedded_data1_july_2024.csv')\n",
    "\n",
    "\n",
    "print(\"Complete\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
