{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loopi\\anaconda3\\envs\\week4\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import datetime\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='process_errors.log', level=logging.ERROR, format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_path = './daum_data/01. preprocessed_daum_data.csv'\n",
    "preprocessed_df = pd.read_csv(open_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-30 00:00:00 2024-07-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df['date'] = pd.to_datetime(preprocessed_df['date'], format = '%Y%m%d')\n",
    "\n",
    "set_preiod = 1 # 날짜 필터 기간 설정, 0 일 경우 데이터 전체\n",
    "# 최근 날짜부터 설정 달까지 데이터프레임 자르기\n",
    "if set_preiod:\n",
    "    recent_date = preprocessed_df['date'].max()\n",
    "    date_preoid = recent_date - pd.DateOffset(months=set_preiod)\n",
    "    pre_copy_df = preprocessed_df[(preprocessed_df['date'] >= date_preoid) & (preprocessed_df['date'] <= recent_date)]\n",
    "else:\n",
    "    pre_copy_df = preprocessed_df.copy()\n",
    "    \n",
    "print(date_preoid, recent_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리 정리\n",
    "del preprocessed_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 66610 entries, 30133 to 760607\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   tag                   66610 non-null  object        \n",
      " 1   date                  66610 non-null  datetime64[ns]\n",
      " 2   article_url           66610 non-null  object        \n",
      " 3   letter_ctn            66610 non-null  int64         \n",
      " 4   word_ctn              66610 non-null  int64         \n",
      " 5   sentence_ctn          66610 non-null  int64         \n",
      " 6   clear_sentence_split  66610 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(3), object(3)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "pre_copy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열로 저장된 데이터를 실제 리스트로 변환\n",
    "def convert_to_list(x):\n",
    "    if isinstance(x, str):  # 데이터가 문자열일 경우만 변환\n",
    "        return ast.literal_eval(x)\n",
    "    return x  # 이미 리스트인 경우 변환하지 않음\n",
    "\n",
    "# 값 리스트화\n",
    "pre_copy_df['clear_sentence_split'] = pre_copy_df['clear_sentence_split'].apply(convert_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66610/66610 [11:18<00:00, 98.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer finished.\n"
     ]
    }
   ],
   "source": [
    "# 문장 처리 함수 (각 프로세스에서 동작)\n",
    "def process_sentences(row):\n",
    "    okt = Okt()\n",
    "    tagged_data_local = []\n",
    "    sentences = row['clear_sentence_split']\n",
    "    sent_id = row['tag']\n",
    "    \n",
    "    try:\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():  # 빈 문장 방지\n",
    "                words = okt.morphs(sentence)\n",
    "                tagged_data_local.append(TaggedDocument(words=words, tags=[sent_id]))\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error tag: {sent_id}: {e}\")\n",
    "        \n",
    "    return tagged_data_local\n",
    "        \n",
    "# 진행률 표시를 위한 함수\n",
    "def process_with_progress(df):\n",
    "    results = Parallel(n_jobs=4)(delayed(process_sentences)(row[1]) for row in tqdm(df.iterrows(), total=len(df)))  # n_job cpu 코어 수\n",
    "    return [doc for result in results for doc in result]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # 진행률 표시 + 병렬 처리\n",
    "    tagged_data = process_with_progress(pre_copy_df)\n",
    "\n",
    "    print('Tokenizer finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티프로세스 print\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def on_epoch_start(self, model):\n",
    "        print(f'Start epoch {self.epoch}')\n",
    "    \n",
    "    def on_epoch_end(self, model):\n",
    "        print(f'Finished epoch {self.epoch}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start Doc2vec modeling.\n",
      "Finished epoch 0\n",
      "Finished epoch 1\n",
      "Finished epoch 2\n",
      "Finished epoch 3\n",
      "Finished epoch 4\n",
      "make model complite. all lenght : 731511\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec 모델 초기화 (병렬 처리 활성화)\n",
    "model = Doc2Vec(\n",
    "    vector_size=100,     # 벡터 크기 (최적화를 위해 크기를 줄임)\n",
    "    window=5,           # 컨텍스트 윈도우 크기\n",
    "    min_count=2,        # 최소 단어 빈도 (빈도수가 낮은 단어 무시)\n",
    "    workers=8,          # 사용하고자 하는 CPU 스레드 수 (최대 CPU 코어 사용)\n",
    "    epochs=5,           # 에포크 수 \n",
    "    dm=1                # Distributed Memory 모델 사용\n",
    ")\n",
    "\n",
    "print('start Doc2vec modeling.')\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs, callbacks=[EpochLogger()])   # 완료시 log 표시\n",
    "\n",
    "model.save(\"./daum_data/doc2vec_daum_model.model\")\n",
    "\n",
    "print(f'make model complite. all lenght : {len(tagged_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
